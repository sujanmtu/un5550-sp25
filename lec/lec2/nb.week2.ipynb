{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0pDt70IFJ59"
   },
   "source": [
    "# Chapter 2: Toolbox for Data Scientists  \n",
    "\n",
    "Let's start with playing around with our first notebook. I will be showing the basics off in Jupyter Lab, but the same tasks could be completed using jupyter notebook, Google Colab, Deepnote, or Github Codespaces. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_t2H2KOGcN7"
   },
   "source": [
    "## Getting Started \n",
    "\n",
    "Let’s start with the first code and import a few libraries that will be helpful.\n",
    "After typing in the code, the cell can be executed by pressing the Ctrl+Enter or SHIFT+Enter keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCpAZZrnO8_y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmwK_RtJGyQM"
   },
   "source": [
    "## Data Frames\n",
    "\n",
    "* A key feature of `pandas` is a fast and efficient DataFrame object for data manipulation \n",
    "* A DataFrame is a tabular data structure, with rows and columns\n",
    "* Let’s learn about DataFrames with some examples \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUGUyIAt706n"
   },
   "source": [
    "\n",
    "### Example 1\n",
    "\n",
    "In this example, we use the `pandas` `DataFrame` object constructor with a dictionary of lists as argument. The value of each entry in the dictionary is the name of the column, and the lists are their values.\n",
    "The `DataFrame` columns can be arranged at construction time by entering a keyword *columns* with a list of the names of the columns ordered as we want. What if the *column* keyword is not used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bZI-fl_Gu8C"
   },
   "outputs": [],
   "source": [
    "# Our first DataFrame, constructed with a dictionary of lists \n",
    "data = {\n",
    "    'year': [2010, 2011, 2012, 2010, 2011, 2012, 2010, 2011, 2012],\n",
    "    'team': [\n",
    "        'FCBarcelona', 'FCBarcelona', 'FCBarcelona', 'RMadrid', 'RMadrid',\n",
    "        'RMadrid', 'ValenciaCF', 'ValenciaCF', 'ValenciaCF'\n",
    "    ],\n",
    "    'wins': [30, 28, 32, 29, 32, 26, 21, 17, 19],\n",
    "    'draws': [6, 7, 4, 5, 4, 7, 8, 10, 8],\n",
    "    'losses': [2, 3, 2, 4, 2, 5, 9, 11, 11]\n",
    "}\n",
    "football = pd.DataFrame(data)\n",
    "football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR-PdtDMIAlU"
   },
   "source": [
    "The result is a table where each entry in the dictionary is a column. The index of each row is created automatically taking the position of its elements inside the entry lists, starting from 0. Although it is very easy to create DataFrames from scratch, most of the time what we will need to do is import chunks of data into a DataFrame structure, we will see how to do this in later examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKOVJN5rHvCo"
   },
   "outputs": [],
   "source": [
    "# create data frame with reordered columns \n",
    "# the new table \"football2\" should have columns of: \n",
    "#   team, year, wins, losses, draws\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6LfholeIJco"
   },
   "source": [
    "### Example 2 \n",
    "\n",
    "Let's look at another small DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZvs8DMuIFNK"
   },
   "outputs": [],
   "source": [
    "country_data = {\n",
    "    'country': ['Canada', 'USA', 'Mexico', 'India', 'Singapore', 'China'],\n",
    "    'capital': [\n",
    "        'Ottawa', 'Washington', 'Mexico City', 'New Delhi', 'Singapore', 'Beijing'\n",
    "    ],\n",
    "    'population': [37.0, 327.2, 130.8, 1356.5, 5.8, 1415.0]\n",
    "}\n",
    "myworld = pd.DataFrame(country_data)\n",
    "\n",
    "# view the DataFrame \n",
    "print(myworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4WWsdm4IPpP"
   },
   "outputs": [],
   "source": [
    "# we can also see the DataFrame just calling the DataFrame variable\n",
    "myworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zL7ZHILIUFU"
   },
   "source": [
    "Notice the difference in printing out the DataFrame using the explicit `print` function or listing the variable itself. \n",
    "\n",
    "Let's now try to slice and access different elements form the DataFrame\n",
    "\n",
    "Pandas has also assigned a \"key\" for each row, in this case, with numerical values from 0 through 5. You can access a subset of rows (observations) using square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmZOqSJYIRwB"
   },
   "outputs": [],
   "source": [
    "myworld[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1jfr0p9La2u"
   },
   "outputs": [],
   "source": [
    "# Examine the \"capital\" column of the myworld DataFrame \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQ48IvMUIpok"
   },
   "source": [
    "Note, what is printed out - whether the range of values is inclusive or exclusive. \n",
    "\n",
    "If you only want one column from a DataFrame, you can put the column name in square brackets. The result will be a Data Series data object (not a Data Frame) because only one column is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0rlarr2Im3P"
   },
   "outputs": [],
   "source": [
    "# Select three columns from the original data\n",
    "#  country, capital, and population \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnHsPRc4DxES"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVzlqgZ-I-Zm"
   },
   "source": [
    "Let's work on a larger data set that we import from a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LUl4ZmvJIrz"
   },
   "source": [
    "### Example 3\n",
    "\n",
    "First, we need to read in the .csv file. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5VnN5u1J36P"
   },
   "outputs": [],
   "source": [
    "# Read in the data from 'population.csv' file \n",
    "pop = pd.read_csv('population.csv')\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUw4GTXLKhX1"
   },
   "source": [
    "We can use the `head()` function to look at the first few rows, and the `tail()` function to look at the bottom few rows (default is 5, you can specify the number to print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43UlFimeKKEr"
   },
   "outputs": [],
   "source": [
    "# use head to look at the first 10 rows\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58f0mQxwKn7o"
   },
   "outputs": [],
   "source": [
    "# use tail to look at the last 8 rows \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYQZU0ZrKvma"
   },
   "source": [
    "If we want to start to look at some statistical information, the `describe()` function summarizes all **numeric** columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3lR0zLpKpey"
   },
   "outputs": [],
   "source": [
    "# examine basic statistics summary of the numeric columns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUjItQrjLCrr"
   },
   "source": [
    "Often, we want to filter data based on some criteria. For example, if we only care about populations above 1 billion,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzSwOlegLHZM"
   },
   "outputs": [],
   "source": [
    "pop[pop['Value'] > 1000000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DiybY6_LR_q"
   },
   "source": [
    "Hmmm... that was less useful than expected.  Let's try to reduce the results by also specifying we are interested in the year 2015.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoxwLr20LLhD"
   },
   "outputs": [],
   "source": [
    "pop[(pop['Value'] > 1000000000) & (pop['Year']==2015)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkuqWnhHLzsv"
   },
   "source": [
    "### 'loc' \n",
    "\n",
    "If we want to select a subset of columns and rows using the labels as our references instead of the positions, we can use `loc` function indexing. \n",
    "\n",
    "`loc` - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html  \n",
    "Access a group of rows and columns by label(s) or a boolean array.\n",
    "* single label, e.g., `6` or `'a'` (6 is a label of the index not an integer position) \n",
    "* list or array of labels, e.g., `['a', 'b', 'c']`\n",
    "* slice object with labels, e.g., `'a':'c'`  \n",
    "Note, contrary to usual python slices, both the start and end are included. \n",
    "* boolean array or the same length as the axis being slided, e.g., [True, False, True]\n",
    "* ... and more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wryJsqX0gGf0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6b7tVApLm1M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z833gP6vL6-k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZqPf76uMMP8"
   },
   "source": [
    "### 'iloc'\n",
    "\n",
    "Let's now select rows/columns based on their integer positions or `iloc` indexing\n",
    "\n",
    "'iloc' - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html  \n",
    "Integer-location based indexing for selection by position (from `0` to `length-1`) may also be used with a boolean array. \n",
    "* integer, e.g., `5`\n",
    "* list or array of integers, e.g., `[3, 2, 4]`\n",
    "* slice object with ints, e.g., `1:5` \n",
    "* boolean array \n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imVFMHFNMJMg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwXfXaxcMSbA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A__XmTNkMUmw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epoGXhFYMbJC"
   },
   "source": [
    "### Grouping \n",
    "\n",
    "A useful way to inspect data is to group according to some criteria.  For example, perhaps it would be nice to group all the data by country, regardless of year. We need to thus aggregate the data in an appropriate fashion. For example, we could take the mean population (over time) for each country.\n",
    "\n",
    "`groupby` - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqXPv_kZMW4P"
   },
   "outputs": [],
   "source": [
    "# Show the mean population for each country \n",
    "group = pop[['Country Name', 'Value']].groupby('Country Name').mean()\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gplUJtTDGtZ3"
   },
   "outputs": [],
   "source": [
    "# Show the standard deviation of the population for each country \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnNawsUggqO2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx1h-E3vMqZc"
   },
   "source": [
    "### Aggregation\n",
    "\n",
    "Once we know how to select the desired data, the next thing we need to know is how to manipulate data. \n",
    "One of the most straightforward things we can do is to operate with columns or rows  using aggregation functions. The following list shows the most common aggregation functions.\n",
    "\n",
    "| Function  | Description | \n",
    "|-----------|-------------|\n",
    "| count()   |Number of non-null observations|  \n",
    "| sum()     |Sum of values|\n",
    "| mean()    |Mean of values            | \n",
    "| median()  |Arithmetic median of values             |\n",
    "| min()     |Minimum|\n",
    "| max()     |Maximum|\n",
    "| prod()    |Product of values|\n",
    "| std()     |Unbiased standard deviation|\n",
    "| var()     | Unbiased variance|\n",
    "\n",
    "The result of all these functions applied to a row or column is always a number. Meanwhile, if a function is applied to a DataFrame or a selection of rows and columns, then you can specify if the function should be applied to the rows for each column  (putting the **axis=0** keyword on the invocation of the function), or it should be applied on the columns for each row (putting the **axis=1** keyword on the invocation of the function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pEkiJF-MkIW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQmFR9TjM2nQ"
   },
   "source": [
    "### Arithmetic Operations\n",
    "\n",
    "Beside these aggregation functions, we can apply operations over all the values in rows, columns or a selection of both. The rule of thumb is that an operation between columns means that it is applied to each row in that column and an operation between rows means that it is applied to each column in that row. For example we can apply any binary arithmetical operation (`+`,`-`,`*`,`/`) to an entire row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8Zwv0v5Mtt-"
   },
   "outputs": [],
   "source": [
    "s = pop['Value'] / 1000000\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfOj2Z2XNA8A"
   },
   "source": [
    "We can apply any function to a DataFrame or Series just putting its name as argument of the apply method. For example, in the following code, we apply the `sqrt` function from the `numpy` library to perform the square root of each value in the `Value` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6q4uY4WM77p"
   },
   "outputs": [],
   "source": [
    "s = pop['Value'].apply(np.sqrt)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiBcWIYxNOFn"
   },
   "source": [
    "Another basic manipulation operation is to set new values in our DataFrame. This can be done directly using the assign operator = over a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Kr84R0QNKuG"
   },
   "outputs": [],
   "source": [
    "pop['ValueNorm'] = pop['Value'] / pop['Value'].max()\n",
    "pop.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjwxuRjBNTGG"
   },
   "source": [
    "### Visualization\n",
    "\n",
    "Lets explore a data visualization. Suppose we were interested in plotting the population of China over time. Lets first create a variable, `cn`, that extracts data involving china, and then plot that new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X3_8NOENRA1"
   },
   "outputs": [],
   "source": [
    "cn = pop[pop['Country Name'] == 'China']\n",
    "cn.plot(x=\"Year\", y=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkJ-pQrChXIA"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Let's start to explore doing some data cleaning - an important job when using real world data which is messy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tucxZ1Gsha1x"
   },
   "source": [
    "## Example 4\n",
    "\n",
    "![iris image indicating petal and sepal structures in the flower](https://pages.mtu.edu/~lebrown/un5550-f20/week1/petal_sepal.jpg)\n",
    "\n",
    "We've been given a data set from our field researchers to develop the demo, which only includes measurements for three types of *Iris* flowers:\n",
    "\n",
    "### *Iris setosa*\n",
    "\n",
    "![iris setosa image](https://pages.mtu.edu/~lebrown/un5550-f20/week1/iris_setosa.jpg)\n",
    "\n",
    "### *Iris versicolor*\n",
    "![iris versicolor image](https://pages.mtu.edu/~lebrown/un5550-f20/week1/iris_versicolor.jpg)\n",
    "\n",
    "### *Iris virginica*\n",
    "![iris virginica image](https://pages.mtu.edu/~lebrown/un5550-f20/week1/iris_virginica.jpg)\n",
    "\n",
    "The four measurements we're using currently come from hand-measurements by the field researchers, but they will be automatically measured by an image processing model in the future.\n",
    "\n",
    "The data set, `iris-data-test.csv` is a slight modificaiton from the famous **Iris** data set.  It has been slightly modified from the publicly available version for demonstration purposes in this notebook. \n",
    "\n",
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvjqNfrMNhgE"
   },
   "outputs": [],
   "source": [
    "# Read in local copy of the data\n",
    "iris_data = pd.read_csv('iris-data-test.csv')\n",
    "iris_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS5yXSx7hjwh"
   },
   "source": [
    "A first thing to notice is that this data set is like many real world data sets and has some missing values - ? on row 6 and NAN on row 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aGZMHSoh17M"
   },
   "source": [
    "### Missing Data \n",
    "\n",
    "We can tell `pandas` to automatically identify missing values if we know that marker that is used to represent the missing values, e.g., NA, NAN, or others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V-qJQBghmEv"
   },
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv('iris-data-test.csv', na_values=['NA'])\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7v89ncbh8xq"
   },
   "source": [
    "We can look at the descriptive statistics of the variables: mean, standard deviation, quartiles, min, and max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GApoaU1Th4f9"
   },
   "outputs": [],
   "source": [
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0IpcKKLiAIg"
   },
   "source": [
    "Let's try to handle the missing values. First, we can drop the rows that containt the missing values (note, this is not something that you always want to do, depends on the size of your data, its distribution, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB4f7DddiArg"
   },
   "outputs": [],
   "source": [
    "iris2 = iris_data.dropna()\n",
    "iris2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRz6qrBZiC0G"
   },
   "source": [
    "We can see that this process changed the number of rows from 151 to 146.\n",
    "\n",
    "Second, let's try to replace the missing values. There are many techniques use to infer or interpolate what a missing value should be replaced with (more on this topic later in the course).\n",
    "\n",
    "Today let's try a naive approach by replacing the missing values with the mean for that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Z7OusvtiB-L"
   },
   "outputs": [],
   "source": [
    "iris3 = iris_data.copy()\n",
    "iris3.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT1k3S5MiKGs"
   },
   "source": [
    "As for most things in Python there are many methods to do this.  First, writing our own approach: find the rows where there are missing values, then replace the values with the mean for that variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPFsQ_tUiPVb"
   },
   "outputs": [],
   "source": [
    "# Get rows where there are missing values\n",
    "mv = iris3[iris3['petal_width_cm'].isnull()].index.tolist()\n",
    "mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoOIvyoqiRkU"
   },
   "outputs": [],
   "source": [
    "# Replace the values with the mean for that variable.\n",
    "iris3.iloc[mv, 3] = iris3['petal_width_cm'].mean()\n",
    "iris3.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJb24P8QiHRL"
   },
   "source": [
    "We could also use functions in Python packages. Let's do this and replace the missing values with the median for that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weYKaWTfiVuu"
   },
   "outputs": [],
   "source": [
    "iris4 = iris_data.copy()\n",
    "iris4 = iris4.fillna(iris3['petal_width_cm'].median())\n",
    "iris4.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VJQR4GRiYpX"
   },
   "source": [
    "### Other errors in Data\n",
    "\n",
    "Let's walk some other issues in the data.\n",
    "\n",
    "There are five classes when there should only be three, meaning there were some coding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri8-cjL6ibFt"
   },
   "outputs": [],
   "source": [
    "iris4['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqTmB0bPif5P"
   },
   "source": [
    "It looks like someone forgot to add \"Iris-\" before some of the \"Iris-versicolor\" entries. Also, there looks like a misspelling of \"Iris-setosa\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKI3GtY3iiFH"
   },
   "outputs": [],
   "source": [
    "iris4.loc[iris4['class'] == 'versicolor', 'class'] = 'Iris-versicolor'\n",
    "iris4.loc[iris4['class'] == 'Iris-setossa', 'class'] = 'Iris-setosa'\n",
    "iris4['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j46pjAe-ilhM"
   },
   "source": [
    "# Visualizations \n",
    "\n",
    "Let's explore more functions to help create plots. \n",
    "\n",
    "We will be using the matplotlib library. If you are familiar with the plotting functions in Matlab, you will see that this library has extremely similar function calls.\n",
    "\n",
    "If you are new to generating plots in Python, please review the examples given in the textbook as well as some examples using the pandas library. https://pandas.pydata.org/pandas-docs/stable/visualization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhnMr21ciyTR"
   },
   "source": [
    "## Example 5 \n",
    "\n",
    "We are going to be using the Iris data set again, but we will be using a \"clean\" version that is publically available.  \n",
    "\n",
    "This code also shows how we can read in data directly from the web (not a file stored on the local machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uObmK6Ypi1Aq"
   },
   "outputs": [],
   "source": [
    "colNames = ['slen', 'swid', 'plen', 'pwid', 'type']\n",
    "df = pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                   header=None,\n",
    "                   sep=',',\n",
    "                   names=colNames)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8sra7UTi41U"
   },
   "source": [
    "### Histograms \n",
    "\n",
    "Let's examine the distribution of values for sepal length - `slen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9mUFVlVi9oj"
   },
   "outputs": [],
   "source": [
    "df.hist(column='slen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmDp4f7CjAa1"
   },
   "source": [
    "We can change some of the plotting options. For example, the number of bins in the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8QkvYU3jCZm"
   },
   "outputs": [],
   "source": [
    "df.hist(column='slen',    # Column to plot\n",
    "        figsize=(5, 4),   # Plot size\n",
    "        bins=20);          # Number of bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q1tA82xjFZq"
   },
   "source": [
    "We can look at the histogram for another column (variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SH59MmbGjIXj"
   },
   "outputs": [],
   "source": [
    "df.hist(column='plen',    # Column to plot\n",
    "        figsize=(6, 5),   # Plot size\n",
    "        bins=15);          # Number of histogram bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqwvCxqMjLH7"
   },
   "source": [
    "Let's now add some additional elements that **should be on all plots - axes labels and titles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kssqb-agjOjz"
   },
   "outputs": [],
   "source": [
    "plt.hist(df['plen'], bins=20)\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Petal Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAuEn0VrjQ1e"
   },
   "source": [
    "### Boxplots \n",
    "\n",
    "Box plots are used to compactly show many pieces of information about a variable distribution including some summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54fzraWujYLl"
   },
   "outputs": [],
   "source": [
    "df['pwid'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgMoiEdOjb4J"
   },
   "outputs": [],
   "source": [
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjhRJfjljacP"
   },
   "source": [
    "Let's change how the plot looks. \n",
    "\n",
    "We may want our plots to look like they were generated with Matlab (above) or with R (below) or some other design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp3Q0BTwjk33"
   },
   "outputs": [],
   "source": [
    "mpl.style.use('ggplot')\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhjaQDlNjnSJ"
   },
   "source": [
    "This plot now looks like it was created using R.\n",
    "\n",
    "There are many other styles available which you can investigate how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gp5nrZ23jozb"
   },
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1npI1o5jr0I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.style.use('fivethirtyeight')\n",
    "df.plot.box()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:un5550] *",
   "language": "python",
   "name": "conda-env-un5550-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
